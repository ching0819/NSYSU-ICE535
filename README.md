# NSYSU ICE535
### 大學時期在中山大學修機器學習課程的練習
*2018修課，2020整理資料上傳github*
* [week01](https://github.com/ching0819/my-library/blob/master/NSYSU%20ICE535/week01.ipynb) **梯度下降、學習率**: 
    * 利用梯度下降法找到函數最小值，並與手算答案驗證
    * early stop 機制
    * 討論學習率與梯度下降的關係 
* [week02](https://github.com/ching0819/my-library/blob/master/NSYSU%20ICE535/week02.ipynb) **單變量線性回歸**: 
    * 自己撰寫程式碼實現單變量線性回歸 
    * 利用 scikit-learn 套件實現單變量線性回歸
    * 離群值對最佳化結果的傷害
    * Data normalize對最佳化過程的幫助
* [week03](https://github.com/ching0819/my-library/blob/master/NSYSU%20ICE535/week03.ipynb) **多變量線性回歸**:     
    * 自己撰寫程式碼實現多變量線性回歸 
    * 利用 SciPy 學習參數
    * 增加模型複雜度對結果的影響
    * cost function的討論

* [week04](https://github.com/ching0819/my-library/blob/master/NSYSU%20ICE535/week04.ipynb) **羅吉斯回歸**:
    * 自己撰寫程式碼實現羅吉斯回歸
    * 利用 SciPy 學習參數
    * 調正 regularization parameters 並討論其影響

* [week05](https://github.com/ching0819/my-library/blob/master/NSYSU%20ICE535/week05.ipynb) **類神經網路**:
    * 自己撰寫程式碼實現分類手寫數字
    * 用 feedforward propagation 與 backpropagation 來學習NN的參數
    * 調正 hyper parameters 並討論其影響
    